% -*- mode: latex; tex-main-file: "paper.tex" -*-

\subsection{Ready \Patch\ Lists}
\label{sec:patch:readylist}

\newcommand{\PReady}[1]{\ensuremath{#1.\textit{ready}}}

Our final important optimization precomputes much of the information
required for the buffer cache to choose a set of \patches\ to write.
%
For each \patch\ $p$ we maintain counts that specify whether or not $p$ is
immediately ready to write to disk.


The buffer cache's main task is to choose sets of \patches\ $P$ that satisfy
the in-flight safety property $\PDepset{P} \subseteq P \cup \PDisk$.
%
Redundant \patch\ graph traversals to calculate valid $P$ sets would
severely limit cache size scalability.
%
\Kudos\ therefore explicitly tracks, for each \patch, how many of its
direct dependencies are in memory or in flight.
%
These counts are updated as \patches\ are added to the system, and as the
system receives notifications that \patches\ have reached the disk.
%
When both counts reach zero, the \patch\ is safe to write, and it is moved
into a \emph{ready list} on its containing block.
%
(\Noop\ \patches\ add a slight complication, since \anoop\ \patch\ ``reaches
the disk'' as soon as all its dependencies reach the disk.  The counting
algorithms propagate this state change automatically.)


Some \patches\ in $P$ may depend on other \patches\ in $P$; however, since
\Kudos\ eliminates all dependency cycles, if $P$ is nonempty then at least
one \patch\ in $P$ depends only on other blocks.
%
When that \patch\ $p$ becomes ready, it will be added to $P$, and \Kudos\
subtracts its count from other \patches\ \emph{on the same block}.
%
This may make more \patches\ on the block ready, which will in turn be added
to $P$, and so forth.


To write a block, the buffer cache thus iterates through the block's ready
list, sending \patches\ to the target block device, until the list is
empty. 
%
The buffer cache can also immediately tell whether a block \emph{could
possibly} be written by checking whether its ready list is empty.
%
On-line maintenance of the ready counts adds some cost to several \patch\
manipulations, but since it saves so much duplicate work in the buffer
cache the resulting system is more efficient by multiple orders of
magnitude---and in particular, CPU time no longer scales superlinearly with
the size of the cache.


\begin{comment}
For a \module\ like the write-back cache to forward \patches\ in a
dependency-preserving order, the \module\ must find \patches\ whose \befores\
are all ``closer to the disk'' (or are also being forwarded as part of the same
block write). We say that such \patches\ are \emph{ready}. 


Each \patch\ has a count of the number of \befores\ it has at block device
modules just as close to the disk as it currently is, and a count of the number
of \befores\ it has which are in flight. When these counts are both zero, it is
ready. A \patch's \before\ counts are incrementally updated as \befores\ are
added and removed and as \beforing\ \patches\ are moved closer to the disk.

Because \Kudos\ makes sure that the \befores\ of a \patch\ are at least as
close to the disk as it is, only directly reachable \beforing\ \patches\ need to
be included in a \patch's \before\ counts. \Noop\ \patches, with the exception
of managed \noop\ \patches\ (which have an explicit owning block device), add a
wrinkle to this simplifying rule, however. They are considered to be as close to
the disk as their \before\ which is the farthest from the disk, in effect,
propagating the distance to the disk metric through them.

When a \before\ count update changes whether a \patch\ is ready to write, the
\patch's inclusion in its block's ready list is updated. To write a block, a
\module\ thus iterates through the block's ready list, sending \patches\ to the
target block device, until the list is empty. Thus instead of having to
repeatedly traverse \patch\ graphs to determine readiness on demand, we have
this information maintained automatically as it changes. This automatic
maintenance adds some cost to forwarding \patches\ and changing the graph
structure, but since it saves so much duplicate work\footnote{The amount of
duplicate work saved is actually superlinear in the size of the write-back
cache.} it is much more efficient.
\end{comment}
