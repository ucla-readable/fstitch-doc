% -*- mode: latex; tex-main-file: "paper.tex" -*-

\section {Evaluation}
\label{sec:evaluation}

We evaluate
%
the effectiveness of \patch\ optimizations,
%
the performance of the \Kudos\ implementation relative to Linux ext2
and ext3,
%
the correctness of the \Kudos\ implementation,
%
and the performance of \patchgroups.
%
This evaluation shows
%
that \patch\ optimizations significantly reduce \patch\ memory and CPU
requirements;
%
that a \Kudos\ \patch-based storage system has overall performance
that is within reason, even though it is slower than Linux in some
benchmarks;
%
that \Kudos\ file systems are consistent after system crashs;
%
and that a \patchgroup-enabled IMAP server performs as well as or
better than the unmodified server.

\subsection{Methodology}

All tests were run on a Dell Precision 380 with a 3.2~GHz Pentium 4
CPU, 2~GB of RAM, and a Seagate ST3320620AS 320~GB 7200~RPM SATA2 disk.
%
All tests use a 10~GB file system and the Linux 2.6.20.1 kernel
with the Ubuntu v6.06.1 distribution.
%
We examine Linux ext2 and ext3 (in ordered and journal modes) and
\Kudos\ ext2 (in asynchronous, soft updates, metadata journal, and
full journal modes), all created with default configurations.
%
There is a notable write durability difference between the default
\Kudos\ and Linux ext2/3 configurations: \Kudos\ presumes a write is
durable after is is on the disk platter (safe) and Linux ext2 and ext3
after it is in the disk cache (unsafe). However, both systems can run
with either durability assumption---we report both results for each.
%
All timing results are the mean over three runs.

To evaluate \patch\ optimizations and \Kudos\ as a whole we ran four
benchmarks.
%
The \emph{untar benchmark} untars and syncs the Linux 2.6.15 source code
from the cached file \texttt{linux-2.6.15.tar} (218~MB).
%
The \emph{delete benchmark}, after unmounting and remounting the file
system following the untar benchmark, deletes the result of the untar
benchmark and syncs.
%
The \emph{PostMark benchmark} emulates the small file workloads seen
on email and netnews servers~\cite{postmark}. We use PostMark v1.5,
configured to create 500 files ranging in size from 500~B to 4~MB;
perform 500 transactions consisting of file reads, writes, creates,
and deletes; delete its files; and finally sync.
%
The modified \emph{Andrew benchmark} emulates a software development
workload.  The benchmark creates a directory hierarchy, copies a
source tree, reads the extracted files, compiles the extracted files,
and syncs. The source code we use for the modified Andrew benchmark is
the Ion window manager, version 2-20040729.

\subsection {Optimization Benefits}

% this table is a command so that we can move its placement without conflicts
\newcommand{\opttable}{
\begin{figure}[t]
\centering
\small
\begin{tabular}{@{}lrrr@{}}
\textbf{Optimization}
        & \textbf{\# \patches} & \textbf{Undo data} & \textbf{System time} \\
% Results are from r3931
% NOTE: also update numbers in \patchoptundo and \patchoptcount
\hline
\multicolumn{4}{@{}c@{}}{\textbf{Untar test}\raise2pt\hbox{\strut}} \\
None
        & 619,740               & 470.43~MB             & 3.44~sec \\
\Nrb\ \patches\
        & 445,927               & 210.88~MB             & 3.09~sec \\
Overlap merging
        & 109,152               & 260.00~MB             & 2.18~sec \\
Both optimizations
        &  67,363               & 0.33~MB               & 2.33~sec \\
\hline
\multicolumn{4}{@{}c@{}}{\textbf{Delete test}\raise2pt\hbox{\strut}} \\
None
        & 299,089               & 1.46~MB               & 0.85~sec \\
\Nrb\ \patches\
        & 41,113                & 0.93~MB               & 0.29~sec \\
Overlap merging
        & 54,665                & 0.96~MB               & 0.33~sec \\
Both optimizations
        &  1,800                & 0.00~MB               & 0.19~sec \\
\hline
\multicolumn{4}{@{}c@{}}{\textbf{PostMark test}\raise2pt\hbox{\strut}} \\
None
        & 4,590,772             & 3,175.28~MB           & 26.44~sec \\
\Nrb\ \patches\
        & 2,550,689             & 1,582.93~MB           & 21.48~sec \\
Overlap merging
        &   542,620             & 1,587.80~MB           & 14.56~sec \\
Both optimizations
        &   617,669             &     0.09~MB           & 14.57~sec \\
\hline
\multicolumn{4}{@{}c@{}}{\textbf{Andrew test}\raise2pt\hbox{\strut}} \\
None
        &  70,922               & 65.63~MB              & 5.38~sec \\
\Nrb\ \patches\
        &  50,381               & 37.05~MB              & 5.43~sec \\
Overlap merging
        &  12,438               & 28.57~MB              & 5.34~sec \\
Both optimizations
        &  11,180               & 0.03~MB               & 5.35~sec \\
\end{tabular}
\caption{Effectiveness of \Kudos\ optimizations.}
\label{f:optdata}
\end{figure}
}

\opttable{}

We evaluate the effectiveness of the \patch\ optimizations discussed in
Section~\ref{sec:patch:optimizations}, in terms of
%
the total number of \patches\ created, amount of undo data allocated,
and system CPU time used.
%
Figure~\ref{f:optdata} shows these results for the untar, delete,
PostMark, and Andrew benchmarks for \Kudos\ ext2 in soft updates mode,
with all combinations of using \nrb\ \patches\ and overlap merging.
The results for metadata and full data journaling are similar.
%
While both optimizations work well alone, the combination of the two
is particularly effective at reducing the amount of undo data.
%
Undo data memory usage is reduced by \patchoptundo,
%
the number of \patches\ created is reduced by \patchoptcount,
%
and system CPU time is reduced by up to 77\%.
\todo{Discuss why both can increase \#patches.}

\begin{comment}
\begin{figure}[t]
\vspace{-0.5\baselineskip}
\centering{
\includegraphics[width=\hsize]{rb_patch_size}
}
\vspace{-0.5\baselineskip}
\caption{\label{fig:patchsize-histo} \Rb\ \patch\ size histogram for a sample
workload (extracting a large archive into ext2). All the \patches\ larger than
63 bytes have been optimized into \nrb\ \patches. \Rb\ \patches\ 4 bytes and
smaller account for about 51\% of all \rb\ \patches.}
\end{figure}
\end{comment}

\subsection {Benchmarks}
\label{sec:eval:bench}

\newcommand{\safe}[1]{\textbf{#1}}
\newcommand{\unsafe}[1]{#1}

% this table is a command so that we can move its placement without conflicts
\newcommand{\benchtable}{
\begin{figure}[tb]
\centering
\small
\begin{tabular}{@{}lrrrr@{}}
\textbf{System} & \multicolumn{1}{c}{\textbf{Untar}} & \multicolumn{1}{c}{\textbf{Delete}} & \multicolumn{1}{c}{\textbf{PostMark}} & \multicolumn{1}{c}{\textbf{Andrew}} \\ \hline
% Results are from r3966, except for postmark (r3972)
% Kudos results are mean over 10
\multicolumn{3}{@{}l}{\emph{\Kudos\ ext2}\raise2pt\hbox{\strut}} & & \\
\safe{soft updates} & \safe{6.2 [2.5]} & \safe{0.9 [0.2]} & \safe{48.2 [14.7]} & \safe{37.8 [5.3]} \\
\safe{meta journal} & \safe{8.5 [2.8]} & \safe{1.5 [0.5]} & \safe{75.6 [16.8]} & \safe{37.6 [5.5]} \\
\safe{full journal} & \safe{12.9 [3.4]} & \safe{1.4 [0.5]} & \safe{99.1 [22.2]} & \safe{37.8 [5.5]} \\
\unsafe{async} & \unsafe{4.2 [1.5]} & \unsafe{0.7 [0.2]} & \unsafe{46.6~~~[8.6]} & \unsafe{37.3 [5.3]} \\
\unsafe{full journal} & \unsafe{10.3 [3.8]} & \unsafe{1.2 [0.5]} & \unsafe{86.3 [25.2]} & \unsafe{37.6 [5.5]} \\ \hline

% Linux results are mean over 3
\multicolumn{3}{@{}l}{\emph{Linux}\raise2pt\hbox{\strut}} & & \\
% safe ordered: r3959
\safe{ext3 ordered} & \safe{16.1 [1.0]} & \safe{4.4 [0.3]} & \safe{33.4 [3.9]} & \safe{37.7 [5.3]} \\
\safe{ext3 journal} & \safe{12.7 [1.2]} & \safe{4.5 [0.2]} & \safe{65.7 [5.0]} & \safe{38.8 [5.0]} \\
\unsafe{ext2} & \unsafe{4.5 [0.7]} & \unsafe{4.6 [0.2]} & \unsafe{30.4 [2.0]} & \unsafe{37.3 [4.9]} \\
\unsafe{ext3 journal} & \unsafe{10.9 [1.1]} & \unsafe{4.3 [0.3]} & \unsafe{57.9 [4.9]} & \unsafe{37.8 [5.0]} \\

%FreeBSD (soft updates) & 23.22 & 15.95 & & \\ 
%FreeBSD (async) & 10.09 & 3.25 & & \\
\end{tabular}
\caption{\label{fig:bench_time} Benchmark times (seconds). System CPU
  times are in square brackets. Safe configurations are \safe{bold},
  unsafe configurations are \unsafe{normal text}.}
\end{figure}
}

We benchmark \Kudos\ and Linux ext2/ext3 for the untar, delete,
PostMark, and Andrew benchmarks. Results are listed in
Figure~\ref{fig:bench_time}.
%
The general result is that \Kudos\ and Linux ext2/ext3 perform
similarly when providing similar durability guarantees. Linux
ext2/ext3 also outperforms \Kudos, and vice versa, in some scenarios.
We explain these differences in the following two paragraphs.

\benchtable{}

While \Kudos\ performs similarly for total time for the untar, delete,
and Andrew benchmarks, during each test \Kudos\ uses significantly
more CPU time than Linux ext2 or ext3 do---up to three times the CPU
time.
%
Higher CPU requirements are an important concern and, though they were
the focus of many of our optimization efforts, remain a weakness
for \Kudos.
\todo{Characterize the additional cpu time. memcpy? patches?}
%
Additionally, while \Kudos\ I/O times are lower than Linux ext2/ext3 I/O
times for the untar and delete benchmarks, we have found that small
block allocation strategy changes can significantly affect I/O time
for many of these benchmarks. This further emphasizes the importance
of the system CPU time difference.

Unlike the untar, delete, and Andrew benchmarks, Linux ext2/ext3
outperforms \Kudos\ at PostMark.
%
We believe the primary contributor to this difference is a difference
in the amount of data read from disk, because of \Kudos's smaller
default cache (64~MB cache vs the 2~GB of ram).  Whereas
Linux ext2/ext3 reads on the order of 100~kB, \Kudos\ reads
480--540~MB. \todo{Use larger cache?}
%
We believe a secondary contributor to this difference is a difference
in the amount of data written to disk. Linux ext2 and Linux ext3 in
ordered journal mode detect that most dirty blocks are no longer
referenced at the end of the test, and so do not write them to disk
(writing only 0.1--0.2~MB). In contrast, \Kudos\ and Linux ext3 in
full journal mode do not do this detection and thus write these blocks
(writing 90--180~MB and 120~MB, respectively). \todo{Update
  not-referenced effectiveness for large postmark.}
%
While we believe that \Kudos\ and its ext2 module probably can be
improved to make this optimization, we have not implemented it.

%This demonstrates that the overhead of using \patches\ in \Kudos\ is not
%entirely unreasonable, but has room for significant improvement.

\subsection {Correctness}
\label{sec:eval:correctness}

In order to check that we had implemented the soft updates rules correctly, we
implemented a \Kudos\ module which crashes the operating system, without
giving it a chance to synchronize its buffers, at a random time during the
untar test.
%
In \Kudos\ asynchronous mode, after crashing, fsck nearly always reported that
the file system contained many references to inodes that had been deleted: the
file system was corrupt.
%
With our soft updates dependencies, the file system was always mostly
consistent: fsck reported that inode reference counts were higher than the
correct values (an expected discrepancy after a soft updates crash).

\subsection {\Patchgroups}
\label{sec:evaluation:uwimap}

% #reviewers who want measurements of all case studies: 1
% #reviewers who want measurements of at least svn and imap studies: 2

To evaluate the performance of the \patchgroup-enabled UW IMAP mail
server (\S\ref{sec:patchgroup:uwimap}) we benchmark a client moving
1,000 messages. The client selects the source mailbox (containing
1,000 2~kB messages), creates the new mailbox, copies each message to
the new mailbox and marks each source message for deletion, expunges
the marked messages, commits the mailboxes, and logs out.

Figure~\ref{fig:imap-compare} shows the results.
%
We divide configurations into the two categories unsafe (drive cache
durability only, a message can be lost if the system loses power) and safe
(drive platter durability).
%
We report total time, system CPU time, and the number of disk write
requests (an indicator of the number of required seeks in safe
configurations).
%
We benchmark
%
\Kudos\ and Linux with the unmodified server (fsync after each message
copy),
%
\Kudos\ with the \patchgroup-enabled server (sync only at the end),
%
and Linux with a server modified to presume a fully journaled file
system (fsync only at the end).
%
Figure~\ref{fig:imap-compare} groups similar results, reporting each
of the following with one entry:
%
\Kudos\ meta and full journal modes,
%
Linux ordered and journal modes,
%
and unsafe/safe \Kudos\ asynchronous mode with/without \patchgroups.

Safe journaled \Kudos\ with \patchgroups\ performs at least as well as
all other \Kudos\ and all Linux configurations, including the unsafe
configurations. Safe journaled \Kudos\ with \patchgroups\ is 11--13
times faster than safe Linux ext2 or ext3 with the unmodified server
and even up to 20\% faster than unsafe Linux ext2 or ext3.
%
\Kudos\ soft updates mode with \patchgroups\ is significantly slower
than \Kudos\ journal modes. As the number of write requests indicate,
each of its \patchgroups\ requires multiple write requests (e.g. to
update the destination mailbox and the destination mailbox's
modification time). In contrast, journaling is able to commit a large
number of copies atomically, using only a small constant number of
requests.
%
\Kudos\ with the unmodified server makes significantly many more
requests than Linux ext2/ext3; we believe this is due to \Kudos\ also
committing file system summary information that Linux does not commit
for the \texttt{fsync} system call.
%
\todo{Discuss full journal optimized server results.}

\begin{figure}[t]
\centering
\begin{tabular}{@{}lrr@{}}
\textbf{System} & \textbf{Time} & \textbf{Writes} \\ \hline

% Results are from r3933
% Commented out results are from r3862

\multicolumn{3}{@{}c@{}}{\textbf{Unsafe}\raise2pt\hbox{\strut}} \\

% NOFUA
\Kudos\ async (pg) & 1.2 [0.3] & 18 \\
%\Kudos\ soft updates (pg) & 11.4 [0.4] & 3,015 \\
%\Kudos\ meta journal (pg) & 1.4 [0.4] & 33 \\
\Kudos\ full journal (pg) & 1.3 [0.5] & 33 \\

% WB
Linux ext2 (fsync) & 1.5 [0.3] & 2,503 \\
%Linux ext3 ordered (fsync) & 2.0 [0.3] & 3,025 \\
Linux ext3 journal (fsync) & 1.8 [0.3] & 2,531 \\ \hline

\multicolumn{3}{@{}c@{}}{\textbf{Safe}\raise2pt\hbox{\strut}} \\

% FUA
%\Kudos\ async (pg) & 1.6 [0.3] & 2,503 \\
\Kudos\ soft updates (pg) & 27.2 [1.2] & 3,015 \\
%\Kudos\ meta journal (pg) & 1.5 [0.4] & 32 \\
\Kudos\ full journal (pg) & 1.5 [0.5] & 32 \\
\Kudos\ full journal (linear) & 1.4 [0.4] & 31 \\

% WT, fsyncs to CHECK/CLOSE
Linux ext3 journal (linear) & 1.2 [0.3] & 26 \\

% FUA, without patchgroups
%\Kudos\ async (pg) & 1.6 [0.3] & 2,503 \\
\Kudos\ soft updates (fsync) & 65.0 [0.3] & 8,083 \\
%\Kudos\ meta journal (pg) & 51.3 [0.4] & 7,111 \\
\Kudos\ full journal (fsync) & 51.0 [0.5] & 7,114 \\

% WT
Linux ext2 (fsync) & 16.7 [0.3] & 2,503 \\
%Linux ext3 ordered (fsync) & 23.9 [0.3] & 3,025 \\
Linux ext3 journal (fsync) & 20.4 [0.3] & 2,531 \\

\end{tabular}
\caption{\label{fig:imap-compare} IMAP benchmark: move 1,000 messages.
  Times are in seconds, writes in number of requests.  System CPU
  times are in square brackets. Consistency protocols: ``fsync'' is
  the unmodified server, ``pg'' uses patchgroups, and ``linear'' presumes
  a fully journaled file system.}
\end{figure}
