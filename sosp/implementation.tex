\section{Implementation}
\label{sec:implementation}

The \Kudos\ prototype implementation runs as a Linux 2.6 kernel module.
%
%% was originally implemented as a stand-alone file system server daemon
%% for a small operating system (called ``KudOS''), then later as a
%% FUSE~\cite{fuse} file system server under Linux or BSD. It currently runs as a
%% Linux kernel module. The FUSE implementation was particularly useful for
%% debugging, but we have found (unsurprisingly) that the Linux kernel module
%% version is best for real-world performance testing and actual use. Due to the
%% complexity involved in maintaining both versions, we eventually dropped the
%% FUSE version.
%
It interfaces with the Linux kernel at the VFS layer and the generic block
device layer.
%
In between is a \Kudos\ module graph that replaces Linux's conventional
file system layers and buffer cache.
%
A small kernel patch informs \Kudos\ of process fork and exit events as
required to update per-process \patchgroup\ state.


During initialization, the \Kudos\ kernel module registers a VFS file system
type with Linux (like ``nfs'' or ``ext2'').
%
Each file system \Kudos\ detects on a specified disk device can then be mounted
from Linux using a command like \mbox{\texttt{mount -t kfs kfs:\textit{name}
/mnt/point}}.
%
Since \Kudos\ provides its own \patch-aware buffer cache, it sets
\texttt{O\_SYNC} on all opened files as the simplest way to bypass the normal
Linux cache and ensure that the \Kudos\ buffer cache obeys all necessary
dependency orderings.


\Kudos\ modules interact with Linux's generic block device layer mainly via
\verb+generic_make_request+.
%
This function sends read or write requests to a Linux disk scheduler, which
may reorder and/or merge the requests before eventually releasing them to
the device.
%
Writes are considered in flight as soon as they are enqueued on the disk
scheduler.
%
A callback notifies \Kudos\ when the disk controller reports request
completion; for writes, this commits the corresponding \patches.
%
The disk safety property requires that the disk controller wait to report
completion until a write has reached stable storage.
%
Most drives instead report completion when a write has reached the drive's
volatile cache.
%
Ensuring the stronger property could be quite expensive, requiring frequent
barriers or setting the drive cache to write-through mode; either choice
seems to prevent older drives from reordering requests.
%
The solution is a combination of SCSI tagged command queuing (TCQ) or SATA
native command queuing (NCQ) with either a write-through cache or ``forced
unit access'' (FUA).
%
TCQ and NCQ allow a drive to independently report completion for multiple
outstanding requests, and FUA is a per-request flag that says the disk
should report completion only after the request reaches stable storage.
%
Recent SATA drives handle NCQ plus write-through caching or FUA exactly as
we would want: the drive appears to reorder write requests, improving
performance dramatically relative to older drives, but reports completion
only when data reaches the disk.
%
We use a patched version of the Linux 2.6.20 kernel with good support for
NCQ and FUA, and a recent SATA2 drive.


\begin{comment}
At the other end of the \Kudos\ \module\ graph, the terminal block device
\modules\ are wrappers for Linux's normal block devices. By using Linux's
generic block layer, \Kudos\ can interface with any existing block device (e.g.
RAM disk, IDE disk, etc.). When the \module\ receives read or write calls, it
passes the requests to Linux via \texttt{generic\_make\_request()}. Linux may
then reorder or merge them, and eventually they are sent to the disk controller.
%
When a request is complete, the disk controller notifies Linux, which in turn
notifies \Kudos. Depending on the hardware configuration, a request being
``complete'' might mean one of two things: first, the data may merely be in the
drive's volatile cache, so that a power outage might cause it to be lost. This
can be a catastrophic disaster, as shown in~\cite{nightingale06rethink}.
Alternately, the data may have been successfully stored on the physical media.
This situation, which is necessary for the strong guarantee \Kudos\ aims to
provide, can be arranged either by disabling the drive's write-back cache, or by
using the ``force unit access'' (FUA) mode when writing to the disk (though a
small patch to the Linux kernel is required to support this mode). Both of these
approaches significantly degrade performance when used alone; additionally,
traditional FUA mode is supported by very few drives\todo{cite something?}.
%
However, using a write-through cache or FUA mode in conjunction with SCSI tagged
command queuing (TCQ) or SATA native command queuing (NCQ) only slightly slows
write performance compared to using the write-back cache without FUA\todo{give
figures to support this claim}, since many write requests may be outstanding at
a time and the drive can choose how to service them in a manner not unlike how
it would choose to write data stored in its volatile cache. Additionally, FUA is
a standard part of the SATA NCQ specification\todo{cite SATA spec}, so all SATA
disks support it when using NCQ.
\end{comment}

\begin{comment}
The Linux kernel must be modified in order to
provide support for \patchgroups.  As a kernel module, there is no way to
get notifications about when processes are created, or when they terminate; this
is necessary to clone the \patchgroup\ scope 
from the parent process when the process is created, and to release all
the \patchgroups\ when it terminates. Ordinarily, this sort of state would be kept
as part of the Linux \texttt{task\_struct} (i.e. process) structure, but this is
not a viable option for a dynamically loadable kernel module. Instead, the
\Kudos\ module keeps this state internally and uses new kernel hooks
to be notified when processes fork or exit. 
%% The patch to add these hooks
%% is based on the ``process events connector'' which was introduced in Linux
%% 2.6.15, and is only about 250 lines long. Without it, \Kudos\ can still operate,
%% but it does not allow \patchgroups.

Our interfaces bypass all Linux caches, because \Kudos\ provides its own
\patch-aware caches (\S\ref{sec:modules:wbcache}) in order to provide its
write-ordering guarantees.

Our current implementation uses Linux's queuing structures for queuing I/O
requests for block devices. Although this is working, there are a couple subtle
problems that we would like to solve in a future version. For instance, we would
like to be able to give more priority to read requests, potentially even
reserving a SCSI TCQ or SATA NCQ command tag for reads only. In the current
implementation, read delay increases noticeably when there are many writes; we
suspect that a factor in this behavior is that the command tags are typically
all used for outstanding writes (since we request that the commands complete
only after the physical media has been written), while the Linux queues are
designed for a different situation: writes complete quickly (to the disk's
cache) and only reads take a long time.
\end{comment}

Future work will require hardening several aspects of our Linux
integration.
%
Integrating \patch\ and dependency support into Linux's native buffer cache
would allow applications to use memory-mapped I/O on \Kudos\ files and
reduce \Kudos's memory usage.
%
We also observe that read delay increases notably when there are many
writes.
%
We suspect that write requests, which for \Kudos\ take far longer than
Linux expects because the drive must delay completion notification, are
using all available command slots; one or more slots should probably be
reserved for reads.
