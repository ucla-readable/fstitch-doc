\subsection{Implementation}
\label{sec:solution:impl}

(talk about how we did some speed optimizations already somewhere in this file)

intro paragraph, we implemented these things... blah blah

\subsubsection{KPL}

must integrate user level file descriptor interface. (why this is
warranted). provides capabilities page.

\subsubsection{UHFS}
\label{sec:solution:impl:uhfs}

If the CFS layer is akin to C and the LFS layer to assembly, the UHFS (Uniform
High level File System) module is a CFS to LFS interpreter. UHFS is intended to
be the common CFS-LFS module for all file systems with an LFS interface; this
includes josfs\_base and does not include devfs\_cfs. UHFS's CFS function
implementations take care of non-block aligned accesses, lower level operations
such as block allocation during write, and orders inter-LFS function call chdesc
dependencies.

uhfs\_write() provides an example of a typical UHFS function. UHFS's client
passes an open file's fid, data to write, and where in the file this data
belongs. uhfs\_write() looks up the fid's associated LFS fdesc and if the below
LFS supports file sizes, looks up the file's current size in bytes.
uhfs\_write() then writes the data a block at a time to the below LFS,
allocating and then appending blocks as the file needs enlargement. Once all
data is written and if the below LFS supports the file size feature,
uhfs\_write() updates the file size metadata.

\subsubsection{josfs\_base}

The josfs\_base module provides low-level operations to the JOS File System.
Its purpose as a base LFS module is to encapsulate all knowledge specific to the
file system. As such, only josfs\_base knows about the free block bitmap and
files with indirect blocks. No other module in the system needs to know the
details of how a JOS File System is laid out on disk. LFS modules such as
josfs\_base only know how to perform micro-ops like allocating a block,
appending a block, and writing a block. For each operation, josfs\_base will
make appropriate changes to the underlying block device, so the structures on
disk correctly reflect the semantics of the operation.

Josfs\_base also supports ``optional'' features such as file size and the
concept of directories. UHFS can query josfs\_base to see what features it
supports and then act accordingly. For the most part, josfs\_base treats
metadata as pure metadata. It is up to UHFS to set file sizes correctly,
although the file size metadata is not necessary for josfs\_base to work. The
exception to this is directory size. When adding a directory entry requires
josfs\_base to allocate a new block, josfs\_base will increase the directory
size, since UHFS is not aware of this.

To support reliability features like soft updates \cite{ganger00soft} and
journalling, josfs\_base orders all writes to the underlying block device in a
safe manner consistant with soft-updates. Additionally, josfs\_base generates
change descriptors, chained in the right dependency order, for use by other
modules in the system.

The josfs\_base module started from JOS's fs.c, but quickly evolved on its own.
It is one of the biggest modules in the system and it took many iterations to
get right. This is partly do to the number of calls a LFS module has to support.
Most of the calls needed to implement some logic and only a few were simple
pass-throughs to the underlying layer. Also, because much of KudOS was a design
in progress, it was not always completely clear how some aspects of LFS would
interact with the rest of the system. Several times, design changes were not
apparent until after implementation.

\subsubsection{josfs\_cfs Legacy Module}

In the beginning of the KudOS file server's development we wanted to begin
testing CFS modules, CFS RPC, and KPL before the LFS and BD layers were ready
for use. The josfs\_cfs module allowed this testing by providing a full file
system, using JOS's existing file server daemon as a back-end. josfs\_cfs's
simplicity also served as a first validation that the CFS interface is flexible
enough to host new and helpful uses.

\subsubsection{Reliable File System Features}

We implemented two types of reliable file system features: soft updates and
journalling. Both use change descriptors to ensure that some disk writes will
occur before others, but what writes exactly they are and how they depend on one
another are completely different.

In journalling, changes to the disk are written to a journal before being
written to the disk itself. After being written to the journal, a single disk
sector (the ``commit record'') is written in the journal that commits the whole
sequence of writes atomically. Afterward, the data is written to the disk, and
once all the data has been written, the commit record is cleared. Should the
system crash before the commit record is written, none of the writes will be
made to the disk, and the filesystem will be in the consistent state it was in
before whatever operation triggered the writes. Should it crash after the commit
record is written, then the journal will be ``replayed'' in order to write all
the information in the journal to the disk. Even if some or all of it had
already been written, writing it again will not cause any problems. Once the
journal has been recovered to the disk, the commit record will be erased and the
filesystem will once again be in a consistent state.

To effect this behavior, we use two modules: a journal LFS module, and a journal
queue BD module. The function of the journal queue BD module is to hold disk
blocks that would otherwise have been written to the disk in a queue until asked
to release them, and it is placed below the base LFS module (as its BD). The
journal LFS module is placed above the base LFS module, and it knows how to
construct, write, and recover the journal. Ordinarily, it keeps the journal
queue BD in a hold state, so that all filesystem changes are queued up. Every so
often (the ``commit interval''), it asks the journal queue BD for all the blocks
in the queue, writes them to the journal, sets up dependencies so that the
journal will be written before the disk blocks themselves, and releases the
queued blocks. This process is always guaranteed to occur at times when the
filesystem is in a consistent state.

FIXME we should put a diagram here

Soft updates is somewhat more pervasive, because unlike full journalling, it
needs to have some information about what a filesystem is and what it means for
it to be ``consistent.'' Briefly, soft updates needs to guarantee that
structures on the disk are always initialized and marked as in use before they
are pointed to, and that all pointers to structures are cleared before the
structures are marked as free or reused. To accomplish this, we need the base
LFS module to help us out a little bit, by giving us ``hints'' (really, change
descriptor dependency information) as to what needs to happen before what for
each of its micro-ops, and we need those small hints to be composed into larger
hints by UHFS. These are relatively small changes to both of these modules, and
they are relatively simple to make because of how much the work is divided up
into individual LFS operations.

The write-back cache, described below, then makes sure that the changes are
written in a safe order, just as it does for journalling above. This is one of
the big advantages of generalizing the write ordering requirements of soft
updates and journalling: they can share a good deal of the more complicated
code.

\subsubsection{wb\_cache}

makes sure that dep graph is satisifed

direct mapped cache. talk about algo used to evict blocks. the algo is
not optimal. in practice it is optimal, but in practice we don't have
very complex graphs. produces ooutput that's serialized and safe for
writing to stable storage.

design philosophy: can't stack the wb cache. it has to know that
writes go to disk in the correct order. sync() to make sure stuff goes
to disk at the correct order.

sure, stacking wb cache seems cool, but why not just put a wb cache
above a disk and call it a day? floating deps down gives no benefit.

you could probably do a wb cache that doesn't honor deps but depends
on this wb cache to honor them. but aht's a problem sucking blocks
down.

\subsubsection{RAID}
\label{sec:solution:impl:raid}

lets you strip or mirror reads/writes to 1 or 2 disks. mirroring
driver can handle disk failure and go into degraded mode where it's a
pass thru. also mirroring can do what geom did where you hot swap in a
new disk, syn, ditch the old disk (w/ help of modman and userland
utilities).

\subsubsection{Loop Device}
\label{sec:solution:impl:loop}

The loop device provides a BD interface to an LFS file. Through change
descriptors and the LFS interface, the loop device is able to easily pass
dependency information to the underlying filesystem, preserving soft updates and
journalling dependencies. To write or sync a block, the loop device sets the
block's BD pointer and block number for use by the LFS's underlying BD, makes
the appropriate LFS call, reverts its changes to the block, and returns.

\subsubsection{Network Block Device}

The network block device is extremely simple. It uses a straightforward
serialization of the BD interface over a TCP connection. During initialization,
it receives the block size and number of blocks from the server. For each read
request, it sends a read command and a block number to the server, and waits for
the block to be returned. For a write request, it sends a write command, block
number, and the block data. Both the client and server (which can run on either
a POSIX system or KudOS itself) required only a few hours to develop and test,
and they fit right into the rest of the system like any other block device.

\subsubsection{Online Configuration}
\label{sec:solution:impl:online}

The modman component is central to most online configuration and introspection,
providing existence, usage, configuration, and status information for CFS, LFS,
and BD module instances. Each module instance registers/unregisters itself with
modman at creation/destruction time and registers/unregisters module instance
usage. modman stores this information to respond to others' queries.

KFS RPC is implemented in a similar manner to CFS RPC: a serialized KFS is used
to communicate between KFS server and clients via KudOS IPC message passing.
Each KFS function is re-implemented as an RPC stub, allowing an object file to
be linked to either the KFS IPC Client or Server library. Client programs are
thus able to reconfigure the kfsd environment using the same functions that
would be used within kfsd.

The program kfsgraph uses KFS RPC to construct a module usage graph, showing
module instance existence, which instances use which others, and instances'
configuration and status. kfsgraph can output this graph to text or to AT\&T's
graphviz dot format. Section~\ref{sec:eval} shows examples of kfsgraph's output.

The programs mount and umount, named for their similarity to the Unix tools of
the same names, provide a general case, easy to use configuration interface.
Given a BD type of IDE, nbd, loop, or an existing BD and a mount point, mount
constructs the given base BD, caches and block resizers as appropriate, a
josfs\_base or wholedisk as appropriate, UHFS, and connects these to the table
classifier at the given mount point. mount optionally allows specification of
whether journalling is to be used or not (and where to journal to), whether to
fsck the filesystem, how large a cache to use, and whether to use a write back
or write through cache. umount takes a mount point and destructs all modules
down the chain that are no longer in use.
