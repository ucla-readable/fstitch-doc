\subsection{UFS implementation}
\label{sec:modules:ufs}

\subsubsection {Overview}
UFS is the modern incarnation of the classic Berkeley Fast File
System~\cite{mckusick84fast} used in 4.2 BSD. The general concepts for UFS, such
as inodes, cylinder groups, and indirect blocks, are well understood. UFS
implementations exist for many popular UNIX-derived operating systems, including
FreeBSD, Solaris, and Mac OS X. Many vendors have added extentions to UFS.
Examples include UFS with journaling on Solaris and UFS with soft updates on
FreeBSD. Linux's ext2 file system has much in common with UFS, since it borrowed
many ideas from FFS. In \Kudos, we implemented the UFS1 file system as an LFS
\module. We chose UFS because it has been extended in many ways. In particular,
it is the only file system that has been extended with both soft updates and
journaling. We chose UFS1 over UFS2, as UFS1 is well established and more widely
supported.

% FIXME: "...crash. Thereby..." is awkward
Soft updates for UFS is one of the biggest innovations in file systems in terms
of lowering the overhead required to provide file system consistency. By
carefully ordering writes to disk, soft updates avoids the need for synchronous
writes to disk or duplicate writes to a journal. Soft updates also guarantees
consistency after a crash, so the system can avoid time-consuming file system
consistency checks using the \emph{fsck}~\cite{mckusick94fsck} tool.
\S\ref{sec:consistency:softupdate} explains soft updates in greater detail.
Another approach to protecting the integrity of the file system is to write
upcoming operations to a journal first. The content and the layout of the
journal varies per implementation, but in all cases, the system can use the
journal to play out or roll back the operations that did not complete as a
result of a crash. Thereby \emph{fsck} can be avoided.
\S\ref{sec:consistency:journal} explains journaling with \chdescs. For a
comparison of journaling versus soft updates for UFS, see
~\cite{seltzer00journaling}.

\subsubsection {Design Philosophy}
As part of the overall \Kudos\ design, the \emph{UHFS} module encompasses all
logic for decomposing higher level CFS calls into lower level LFS calls. The
finer granularity of LFS calls divides the problem space into smaller chunks.
Since the issue of how to tie the LFS micro-ops together has already been
solved, file system \module\ developers can give more attention to the
particulars of the file system, such as, how to allocated a new filename and
how to lookup the Nth data block for a file. To show how this simplifies the
developmment process, consider the VFS write() call, which has the task of
writing N bytes of data to a file at a given offset. In \Kudos, the problem is
well defined and requires the implementation of these four LFS calls:
get\_file\_block(), allocate\_block(), append\_block(), and write\_block().
Additionally, the granularity of calls at the LFS layer makes it an appropriate
layer for inserting test harnesses and developing file system unit tests.

In accordance with our ideas on the division of responsibilities between the
file system \module\ and higher \modules, we chose to keep properties specific
to UFS (such as the UFS on-disk format and rules governing block allocation)
hidden within the file system \module. Although file systems can have uncommon
requirements, LFS is flexible enough to accommodate many of them. One problem
we ran into concerns UFS and its use of fragments and blocks. In UFS, typically
a block is divided into 8 equal sized fragments. For space efficiency, UFS
allocates fragments to small files. Once a file gets big enough to require the
use of indirect blocks, then UFS changes its allocation policy and starts
allocating blocks for speed. To implement this property of UFS, we used
fragments as the basic block size. For large files, our UFS \module\ internally
allocates a block, but returns only the first fragment in that block at the LFS
level. The next 7 allocation calls will be no-ops that simply return the
subsequent fragments in the allocated block. Overall, we believe most
conventional file systems fit within the bounds set by the LFS interface.

In order to provide the rest of the system with write-ordering requirements for
soft updates, the UFS \module\ creates \chdescs\ for all its changes to the
disk, and connects them to form configurations that achieve soft updates
consistency. Unlike FreeBSD's soft updates implementation, once the dependencies
have been created, UFS no longer needs to concern itself with the \chdescs\ it
has created. The block device subsystem will track and enforce the \chdesc\
orderings.

\begin{figure}[htb]
  \centering
  \includegraphics[width=108pt]{fig/figures_4}
  \caption{\label{fig:ufsmodules} The UFS \module\ is itself composed of
  sub-\modules. The UFS base \module\ holds the core code that does not
  vary, while components that should be flexible, such as those that relate
  to block/inode allocation, cylinder groups, directory entries, and the
  superblock, can be easily exchanged.}
\end{figure}

\subsubsection {Modularity}
Previously, \Kudos\ used a minimal file system called JOSFS. Even though JOSFS
is extremely simple, at the time it was the largest \module\ in \Kudos\ in
terms of lines of code. This is from the fact that much of the actual work
occurs in the file system \modules. For instance, most \chdescs\ in the system
are created when a file system \module\ needs to write to disk. With a real
file system like UFS, a monolithic version will easily be 3 to 4 times bigger
than JOSFS. In earlier version of the \Kudos\ UFS implementation, having one
monolithic \module\ made it difficult to change the algorithms and policies
for particular parts of UFS. In addition, the large amount of code for one
\module\ made it more difficult to manage.

% FIXME: Christina didn't like this paragraph
From our experiences with JOSFS, we realized that UFS would become harder to
maintain as it grew in size. We failed several times trying to come up with a
way to further divide the file system module. The problem of how to generalize
the subdivision within a file system is a difficult one, since not all file
systems share the same characteristics. In light of this issue, we decided to
have specialized interfaces specific to each file system \module. As we
implement more file system \modules, we will discover commonalities to help
solve the subdivision problem.

% FIXME: Christina doesn't like "refactored"
Applying our modularity philosophy to UFS, we refactored the file system
\module\ and separated many parts into sub-\modules\ internal to UFS, as shown
in Figure~\ref{fig:ufsmodules}. Within the UFS \module, the \emph{base} module
contains the core code for the file system. Using object-orientation
techniques, we encapsulated the code for data structures in the file system,
like the superblock and the cylinder groups. We also recognized two locations
where we can apply different search algorithms. One is with respect to the
allocation functions for blocks, fragments, and inodes. The other is for
searching and writing directory entries (see Figure~\ref{fig:moduleinterface}).
In addition to making the code easier to manage, having a modular file system
means it is easy to try out new algorithms. Currently we have two allocator
modules as a proof of concept for modularity.

\begin{figure}[htb]
Cylinder Group Interface:\\
\begin{scriptsize}
\texttt{const UFS\_cg\_t * read(int num);}\\
\texttt{int write\_time(int num, int value, chdesc\_t ** head);}\\
\texttt{int write\_rotor(int num, int value, chdesc\_t ** head);}\\
\texttt{int write...}\\
\texttt{int sync(int num, chdesc\_t ** head);}
\end{scriptsize}\\
\\
Allocator Interface:\\
\begin{scriptsize}
\texttt{int find\_free\_block(fdesc\_t * file, int purpose);}\\
\texttt{int find\_free\_frag(fdesc\_t * file, int purpose);}\\
\texttt{int find\_free\_inode(fdesc\_t * file, int purpose);}
\end{scriptsize}
\caption{\label{fig:moduleinterface} UFS Internal Module Interfaces}
\end{figure}

The UFS cylinder group module interface regulates access to the cylinder
groups. While there is unrestricted read access to cylinder groups, the
interface limits write access to certain fields within the \emph{UFS\_cg}
struct. This is because, under normal operations, fields like the number of
data blocks per cylinder group remains constant. The cylinder group module can
also define the policy for when changes to the cylinder group goes to disk.
It can, for example, make the policy ``write-through'' and have all changes
immediately go to disk. However, choosing this policy means on every block
allocation, UFS needs to write to disk \emph{cg\_rotor}, the position of the
last used block. To avoid performance hits like this, we implemented the
``write-back'' policy instead. To support flushing dirty data to disk, the
cylinder group module interface also has a sync call.

The UFS allocator module interface has similar methods for allocating blocks,
fragments, and inodes. All three methods take in a \emph{file descriptor} and
a \emph{purpose} variable. The UFS \emph{file descriptor} contains all relevant
information pertaining to a given file, including an in-memory copy of the
file's inode. The intent of the \emph{purpose} variable, is to provide hints to
the allocator about what the newly allocated resource will be used for. Given
these two pieces of information, as well as cylinder group information from the
previously mentioned module, UFS allocator modules can make informed decisions
to allocate resources in an efficient manner.

\begin{figure}[htb]
  \centering
  \includegraphics[width=192pt]{fig/figures_6}
  \caption{\label{fig:chdescarrange} Change descriptor dependencies, when
  not strictly needed, restrict the possible choices for write ordering.
  This results in suboptimal write ordering and more scans through the
  \chdescs\ for \Kudos. On the left, \chdescs\ C1, C2, and C3 can be written
  in any order. Only one ordering is possible on the right.}
\end{figure}

\subsubsection {Change Descriptor Arrangements}
While optimizing our UFS implementation, we gained some insight and found a
couple practices critical to good performance. First, do not create unnecessary
dependencies between \chdescs. Doing so artificially limits the commit order
for \chdescs, which results in bad performance for several reasons. Not only
will unneeded dependencies force the disk to do more writes and seeks, but
\Kudos\ will have to scan through the \chdesc\ graph multiple times, since the
dependencies prevent the \chdescs\ from being flushed out to disk at once.

In Figure~\ref{fig:chdescarrange}, we have two possible arrangements for three
byte \chdescs. The noop \chdesc\ represents a root node that can reach all
other \chdescs. In the parallel arrangement on the left, \Kudos\ has the
freedom to write \chdescs\ $C_1$, $C_2$, and $C_3$ to disk in any order. All
three \chdescs\ can be marked writable with one graph traversal. In the serial
arrangement on the right, there exists only one valid write ordering. For
\Kudos\ to write this arrangement out to disk, it will have to scan through
the graph three times, since \chdesc\ $C_n$ cannot be marked as writable until
$C_{n-1}$ has been written.
An instance like this came up because our UFS implementation frequently writes
the \emph{cylinder group summaries} out to disk. By simply changing the
arrangement between three \chdescs\ created in a single function, UFS got a
33\% speed increase for several common file operations.

A corollary of this observation is to create \chdescs\ of the minimal size to
avoid accidental overlaps, which in turn, creates unnecessary dependencies.
\Chdescs can represent changes to regions as small as one byte, and as large
as an entire block. Many times, it can be tedious for developers to calculate
exactly what parts in a large data structure have been modified and need to be
written to disk. As such, laziness will result in the creation of \chdescs\
for the entire data structure. Doing this can be detrimental to performance,
as shown in Figure~\ref{fig:overlap}.

An occurrance of this problem came up for inodes, where we make several
independent modifications to different fields within an inode. In principle,
the \chdescs\ created are independent of one another. Previously, because we
did not take the time to calculate the exact offsets and lengths for the fields
that changed, we just created a \chdesc\ for the entire inode every time we
modified any part of the inode. Thus all changes to any particular inode would
always overlap, causing unnecessary dependencies. Our solution to this problem
is a utility function called \texttt{chdesc\_create\_diff()}, which compares a
modified copy of a data structure to the original, and creates a minimal set of
\chdescs\ accordingly. Due to the frequent use of inodes, one simple use of
\texttt{chdesc\_create\_diff()} in the UFS inode functions reduced \chdesc\
graph traversal time significantly.

\begin{figure}[htb]
  \centering
  \includegraphics[width=64pt]{fig/figures_5}
  \caption{\label{fig:overlap} On inode 17, the gray regions represent
  modified fields that do not overlap. If \chdesc\ A and \chdesc\ B are
  exactly the size of the gray regions, then there is no implicit dependency.
  Making \chdescs\ for the entire inode data structure will, in turn, make
  one \chdesc\ depend on the other because they overlap.}
\end{figure}

\subsubsection {Future Improvements}
Our UFS implementation is usable for everyday purposes. However, there are
some features we do not have. For example, we do not support symbolic links,
triple indirect blocks, and sparse files. The first two can easily be
implemented given time. Sparse file support will require the LFS interface to
be aware of files with holes. This also means the layer immediately above the
LFS interface may need to adjust some of the assumptions it currently makes
about files and block allocation.

There are also auxiliary on-disk data structures that assist the resource
allocation algorithms. We currently ignore many of them, partially because
our basic algorithms do not use them, and partially because documentation
explaining what those data structures represent is sparse. Over time, we
hope to improve our UFS \module\ with more sophisticated allocation
algorithms, as the infrastructure for this already exists.

% FIXME: we don't have to read direntries multiple times anymore
Having a modular system also means there are places where we are less
efficient than a more integrated solution. Although we have removed some
of the redundancy, some still exist. One example is having to read directory
entries multiple times during lookup operations. Coupled with our naive
directory search implementation, we can see why \Kudos\ has not reached
optimal performance.

For rare cases when errors occur, UFS oftentimes undoes the operation by
creating \chdescs\ that reverse the original operation. We hope future
versions of \Kudos\ will be able to automatically detect this sort of
arrangement of \chdescs\ and coalesce them into a \noop. Another idea is to
have some mechanism for voiding \chdescs\ that the file system has already
sent down to the block device layer.
